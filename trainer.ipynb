{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import tokens\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleared CUDA memory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaif Khan\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\cuda\\memory.py:330: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kaif Khan\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\cuda\\memory.py:356: FutureWarning: torch.cuda.reset_max_memory_cached now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "torch.cuda.reset_accumulated_memory_stats()\n",
    "torch.cuda.reset_max_memory_allocated()\n",
    "torch.cuda.reset_max_memory_cached()\n",
    "# Optionally, you can also use the following command to reset the memory allocator\n",
    "# torch.cuda.memory._record_memory_history(enabled=False)\n",
    "print(\"Cleared CUDA memory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total GPU Memory: 6.00 GB\n",
      "Allocated GPU Memory: 0.00 GB\n",
      "Reserved GPU Memory: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def check_gpu_memory():\n",
    "    total_memory = torch.cuda.get_device_properties(0).total_memory\n",
    "    allocated_memory = torch.cuda.memory_allocated(0)\n",
    "    reserved_memory = torch.cuda.memory_reserved(0)\n",
    "\n",
    "    print(f\"Total GPU Memory: {total_memory / (1024 ** 3):.2f} GB\")\n",
    "    print(f\"Allocated GPU Memory: {allocated_memory / (1024 ** 3):.2f} GB\")\n",
    "    print(f\"Reserved GPU Memory: {reserved_memory / (1024 ** 3):.2f} GB\")\n",
    "\n",
    "# Example usage\n",
    "check_gpu_memory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('english_to_index.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "english_to_index = {eval(key) : val for key,val in data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('index_to_english.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "index_to_english = {eval(key) : eval(val) for key,val in data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hindi_to_index.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "hindi_to_index = {eval(key) : val for key,val in data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('index_to_hindi.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "index_to_hindi = {eval(key) : eval(val) for key,val in data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'hearing ', '�समें ')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_english[4567], index_to_hindi[10000].decode('utf-8', errors='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('english_sentences.txt', 'r', encoding='utf-8') as f:\n",
    "    EngData = f.readlines()\n",
    "\n",
    "with open('hindi_sentences.txt', 'r', encoding='utf-8') as f:\n",
    "    HindiData = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('however paes who was partnering australias paul hanley could only go as far as the quarterfinals where they lost to bhupathi and knowles\\n',\n",
       " 'आस्ट्रेलिया के पाल हेनली के साथ जोड़ी बनाने वाले पेस मियामी में क्वार्टरफाइनल तक ही पहुंच सके क्योंकि इस दौर में उन्हें भूपति और नोल्स ने हराया था।\\n')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EngData[0],HindiData[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_sentences = [sentence.rstrip('\\n').lower() for sentence in EngData]\n",
    "Hindi_sentences = [sentence.rstrip('\\n') for sentence in HindiData]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['however paes who was partnering australias paul hanley could only go as far as the quarterfinals where they lost to bhupathi and knowles',\n",
       "  'whosoever desires the reward of the world with allah is the reward of the world and of the everlasting life allah is the hearer the seer',\n",
       "  'the value of insects in the biosphere is enormous because they outnumber all other living groups in measure of species richness'],\n",
       " ['आस्ट्रेलिया के पाल हेनली के साथ जोड़ी बनाने वाले पेस मियामी में क्वार्टरफाइनल तक ही पहुंच सके क्योंकि इस दौर में उन्हें भूपति और नोल्स ने हराया था।',\n",
       "  'और जो शख्स अपने आमाल का बदला दुनिया ही में चाहता है तो ख़ुदा के पास दुनिया व आख़िरत दोनों का अज्र मौजूद है और ख़ुदा तो हर शख्स की सुनता और सबको देखता है',\n",
       "  'जैवमंडल में कीड़ों का मूल्य बहुत है क्योंकि प्रजातियों की समृद्धि के मामले में उनकी संख्या अन्य जीव समूहों से ज़्यादा है।'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_sentences[:3], Hindi_sentences[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99737, 99737)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(english_sentences), len(Hindi_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_sentences = english_sentences[:50000]\n",
    "Hindi_sentences = Hindi_sentences[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 50000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(english_sentences), len(Hindi_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_sequence_length = 100\n",
    "\n",
    "# def is_valid_length(sentence, typee):\n",
    "#     ids = tokens.encode(sentence, typee)\n",
    "\n",
    "#     return len(ids) < max_sequence_length-2\n",
    "\n",
    "# valid_index = []\n",
    "\n",
    "# for i in range(len(english_sentences)):\n",
    "#     if( is_valid_length(english_sentences[i], 'encoder') and is_valid_length(Hindi_sentences[i], 'decoder') ):\n",
    "#         valid_index.append(i)\n",
    "\n",
    "\n",
    "max_sequence_length = 100\n",
    "with open('valid_index_100.pkl', 'rb') as file:\n",
    "    # Load the data from the file\n",
    "    valid_index = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 9394)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(valid_index), len(valid_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 9394)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(english_sentences), len(valid_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('valid_index_100.pkl', 'wb') as f:\n",
    "#     # Dump the list into the file\n",
    "#     pickle.dump(valid_index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hindi_sentences = [Hindi_sentences[i] for i in valid_index]\n",
    "english_sentences = [english_sentences[i] for i in valid_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): Encoder(\n",
       "    (sentence_embedding): SentenceEmbedding(\n",
       "      (embedding): Embedding(55003, 512)\n",
       "      (position_encoder): PositionalEncoding()\n",
       "    )\n",
       "    (layers): SequentialEncoder(\n",
       "      (0): EncoderLayers(\n",
       "        (attention): MultiheadAttention(\n",
       "          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm): LayerNormalization()\n",
       "        (feedforward): PositionwiseFeedForward(\n",
       "          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (sentence_embedding): SentenceEmbedding(\n",
       "      (embedding): Embedding(75003, 512)\n",
       "      (position_encoder): PositionalEncoding()\n",
       "    )\n",
       "    (layers): SequentialDecoder(\n",
       "      (0): DecoderLayers(\n",
       "        (attention): MultiheadAttention(\n",
       "          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm): LayerNormalization()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (feedforward): PositionwiseFeedForward(\n",
       "          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (crossattention): CrossMultiHeadAttention(\n",
       "          (kv_layer): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (q_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=75003, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformer import Transformer\n",
    "d_model = 512\n",
    "max_seq_len = max_sequence_length\n",
    "num_head = 8\n",
    "head_dim = d_model // num_head\n",
    "drop_prob = 0.1\n",
    "ffn = d_model*2\n",
    "encoder_type = 'encoder'\n",
    "decoder_type = 'decoder' \n",
    "n_layers = 1\n",
    "start_token = b'<START>'\n",
    "end_token = b'<END>'\n",
    "padding_token = b'<PAD>'\n",
    "\n",
    "transformer = Transformer(d_model, \n",
    "                          max_seq_len, \n",
    "                          num_head, \n",
    "                          head_dim, \n",
    "                          drop_prob, \n",
    "                          english_to_index, \n",
    "                          ffn, hindi_to_index, \n",
    "                          encoder_type, decoder_type, \n",
    "                          n_layers, start_token, \n",
    "                          end_token, padding_token)\n",
    "transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextData(Dataset):\n",
    "    def __init__(self, english_sentences, hindi_sentences) -> None:\n",
    "        super().__init__()\n",
    "        self.english_sentences = english_sentences\n",
    "        self.hindi_sentences = hindi_sentences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.english_sentences)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.english_sentences[index], self.hindi_sentences[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TextData(english_sentences, Hindi_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('they are not seen anywhere', 'दोनों ही कहीं भी दिखाई नहीं पड़ रहे।')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07577382830185518"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "leraning_rate = random.uniform(0.001, 1)\n",
    "leraning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaif Khan\\AppData\\Local\\Temp\\ipykernel_388\\2753313046.py:7: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  nn.init.xavier_uniform(params)\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "criterian = nn.CrossEntropyLoss(ignore_index=hindi_to_index[padding_token], reduction='none')\n",
    "\n",
    "for params in transformer.parameters():\n",
    "    if params.dim() > 1:\n",
    "        nn.init.xavier_uniform(params)\n",
    "\n",
    "optim = torch.optim.Adam(transformer.parameters(), lr=leraning_rate)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEG_INFTY = -1e9\n",
    "# NEG_INFTY = float('-inf')\n",
    "\n",
    "def create_masks(eng_batch, hn_batch):\n",
    "    max_sequence_length = 100\n",
    "    num_sentences = len(eng_batch)\n",
    "    look_ahead_mask = torch.full([max_sequence_length, max_sequence_length], True)\n",
    "    look_ahead_mask = torch.triu(look_ahead_mask, diagonal=1)\n",
    "\n",
    "    encoder_padding_mask = torch.full([num_sentences, max_sequence_length, max_sequence_length], False)\n",
    "    decoder_padding_mask_self_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length], False)\n",
    "    decoder_padding_mask_cross_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length], False)\n",
    "\n",
    "    for idx in range(num_sentences):\n",
    "        eng_sentence_length, hn_sentence_length = len(tokens.encode(eng_batch[idx], 'encoder')), len(tokens.encode(hn_batch[idx], 'decoder'))\n",
    "        eng_tokens_to_padding_mask = np.arange(eng_sentence_length+1, max_sequence_length)\n",
    "        hn_tokens_to_padding_mask = np.arange(hn_sentence_length+1, max_sequence_length)\n",
    "\n",
    "        encoder_padding_mask[idx, :, eng_tokens_to_padding_mask] = True\n",
    "        encoder_padding_mask[idx , eng_tokens_to_padding_mask, :] = True\n",
    "\n",
    "        decoder_padding_mask_self_attention[idx, :, hn_tokens_to_padding_mask] = True\n",
    "        decoder_padding_mask_self_attention[idx, hn_tokens_to_padding_mask, :] = True\n",
    "\n",
    "        decoder_padding_mask_cross_attention[idx, :, eng_tokens_to_padding_mask] = True\n",
    "        decoder_padding_mask_cross_attention[idx, hn_tokens_to_padding_mask, :] = True\n",
    "\n",
    "    encoder_self_attention_mask = torch.where(encoder_padding_mask, NEG_INFTY, 0)\n",
    "    decoder_self_attention_mask =  torch.where(look_ahead_mask + decoder_padding_mask_self_attention, NEG_INFTY, 0)\n",
    "    decoder_cross_attention_mask = torch.where(decoder_padding_mask_cross_attention, NEG_INFTY, 0)\n",
    "    return encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH :- 0\n",
      "Iteration 0 : 2.5266993045806885\n",
      "English : share videos\n",
      "Translation : वीडियो क्लिप शेयर किए\n",
      "Predicted length :-  54\n",
      "Hindi Prediction :- �त���� ��������� �����������थ � ोत�� त�\n",
      "Generated Tokens :-  [164, 224, 164, 164, 164, 165, 165, 224, 164, 32, 164, 164, 32, 164, 164, 164, 164, 165, 165, 32, 164, 164, 164, 164, 165, 164, 224, 224, 224, 224, 164]\n",
      "Evaluation Of himandri and bindu rani both friends were from karnals salwan village :-- \n",
      "Generated :-  ��������� �� ������ �����������\n",
      "Iteration 100 : 2.6060941219329834\n",
      "English : bajaj auto in search of a winner\n",
      "Translation : बजाज ऑटो  खेल में फिर से वापसी के आसार\n",
      "Predicted length :-  100\n",
      "Hindi Prediction :- ����������������  त���� ������ ��त�� थ�� त��थथ॥ त�� ��थ���त�\n",
      "Generated Tokens :-  [164, 224, 164, 139, 224, 164, 224, 224, 164, 224, 224, 164, 224, 165, 224, 224, 224, 224, 164, 224, 224, 165, 224, 32, 32, 224, 164, 164, 224, 165, 224, 224, 164, 224, 32, 224, 164, 224, 224, 165, 224, 224, 164, 224, 32, 224, 164, 139, 224, 164, 164, 224, 164, 224, 32, 224, 164, 165, 224, 165, 224, 32, 224, 164, 164, 224, 164, 224, 224, 164, 165, 224, 164, 165, 224, 165, 165, 32, 224, 164, 164, 224, 165, 224, 32, 224, 164, 224, 224, 164, 165, 224, 164, 224, 224, 164, 224, 164, 164, 164]\n",
      "Evaluation Of himandri and bindu rani both friends were from karnals salwan village :-- \n",
      "Generated :-  �����������������������  ��������� ��������� ��������� ������ ��������������� ������ ���������������\n",
      "Iteration 200 : 2.444226026535034\n",
      "English : this had led to strained relations between the two\n",
      "Translation : इससे दोनों के संबंधों में दरार आ गई।\n",
      "Predicted length :-  100\n",
      "Hindi Prediction :- �थऋ� ो ��ो��॥�� तो थ��ऋ��� �ो� � � �ो� � � �� �� �� � � � तत।�����\n",
      "Generated Tokens :-  [164, 224, 164, 165, 224, 164, 165, 224, 164, 165, 224, 165, 139, 32, 224, 224, 164, 224, 165, 139, 224, 164, 224, 224, 165, 165, 224, 164, 224, 32, 224, 164, 164, 224, 165, 139, 32, 224, 164, 165, 224, 164, 224, 224, 164, 139, 224, 164, 224, 224, 32, 164, 224, 165, 139, 224, 32, 164, 32, 224, 32, 224, 224, 165, 139, 224, 32, 164, 32, 224, 32, 164, 224, 32, 224, 224, 32, 224, 224, 32, 224, 32, 224, 32, 224, 32, 224, 164, 164, 224, 164, 164, 224, 165, 164, 164, 164, 164, 164, 164]\n",
      "Evaluation Of himandri and bindu rani both friends were from karnals salwan village :-- \n",
      "Generated :-  ������������� ��������������� ������ ������������� ����� � � ����� � � �� �� �� � � � ��������������\n",
      "Iteration 300 : 2.456533670425415\n",
      "English : they were there\n",
      "Translation : वहां उन्होंने\n",
      "Predicted length :-  100\n",
      "Hindi Prediction :- �त�� ���� ऋ������� ो������ो��������������������������������������������������������������\n",
      "Generated Tokens :-  [164, 224, 164, 164, 164, 164, 32, 224, 164, 224, 224, 164, 224, 32, 224, 164, 139, 224, 164, 224, 224, 165, 224, 224, 224, 32, 224, 165, 139, 224, 224, 224, 224, 224, 224, 224, 165, 139, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164]\n",
      "Evaluation Of himandri and bindu rani both friends were from karnals salwan village :-- \n",
      "Generated :-  ������ ������ ����������� ��������������������������������������������������������������������������\n",
      "Iteration 400 : 2.489755868911743\n",
      "English : then you will receive a reference number\n",
      "Translation : इसके बाद आपको एक टोकन नंबर मिलेगा\n",
      "Predicted length :-  100\n",
      "Hindi Prediction :- �ऋथतो ऋ��त ��ऋतो ��त ����त� � � ������� ��� ����त�त����������\n",
      "Generated Tokens :-  [164, 224, 164, 165, 224, 164, 165, 224, 164, 164, 224, 165, 139, 32, 224, 164, 139, 224, 164, 224, 224, 164, 164, 32, 224, 164, 224, 224, 164, 139, 224, 164, 164, 224, 165, 139, 32, 224, 164, 224, 224, 164, 164, 32, 224, 164, 224, 224, 165, 224, 224, 164, 164, 224, 32, 224, 32, 224, 32, 224, 224, 164, 224, 224, 164, 224, 224, 164, 224, 32, 224, 164, 224, 224, 164, 32, 224, 164, 224, 224, 165, 139, 224, 164, 164, 224, 164, 224, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164]\n",
      "Evaluation Of himandri and bindu rani both friends were from karnals salwan village :-- \n",
      "Generated :-  ������������� ��������� ������������ ������ ���������� � � ���������� ����� ������������������������\n",
      "EPOCH :- 1\n",
      "Iteration 0 : 2.4597249031066895\n",
      "English : share videos\n",
      "Translation : वीडियो क्लिप शेयर किए\n",
      "Predicted length :-  31\n",
      "Hindi Prediction :- �त���� � ������ �त������\n",
      "Generated Tokens :-  [164, 224, 164, 164, 164, 165, 165, 224, 164, 32, 164, 164, 32, 164, 164, 164, 164, 165, 165, 32, 164, 164, 164, 164, 165, 164, 224, 224, 224, 224, 164]\n",
      "Evaluation Of himandri and bindu rani both friends were from karnals salwan village :-- \n",
      "Generated :-  ��������� �� ������ �����������\n",
      "Iteration 100 : 2.677321195602417\n",
      "English : bajaj auto in search of a winner\n",
      "Translation : बजाज ऑटो  खेल में फिर से वापसी के आसार\n",
      "Predicted length :-  100\n",
      "Hindi Prediction :- �ऋ���������������  त���� ������� ��त�� थो त��थथ॥ त��� ��थ���त�\n",
      "Generated Tokens :-  [164, 224, 164, 139, 224, 164, 224, 224, 164, 224, 224, 164, 224, 165, 224, 224, 224, 224, 164, 224, 224, 165, 224, 32, 32, 224, 164, 164, 224, 165, 224, 224, 164, 224, 32, 224, 164, 224, 224, 165, 224, 224, 164, 224, 32, 224, 164, 139, 224, 164, 164, 224, 164, 224, 32, 224, 164, 165, 224, 165, 224, 32, 224, 164, 164, 224, 164, 224, 224, 164, 165, 224, 164, 165, 224, 165, 165, 32, 224, 164, 164, 224, 165, 224, 32, 224, 164, 224, 224, 164, 165, 224, 164, 224, 224, 164, 224, 164, 164, 164]\n",
      "Evaluation Of himandri and bindu rani both friends were from karnals salwan village :-- \n",
      "Generated :-  �����������������������  ��������� ��������� ��������� ������ ��������������� ������ ���������������\n",
      "Iteration 200 : 2.4348907470703125\n",
      "English : this had led to strained relations between the two\n",
      "Translation : इससे दोनों के संबंधों में दरार आ गई।\n",
      "Predicted length :-  100\n",
      "Hindi Prediction :- �थथ� ो ��ो��॥�� त॥ थ��ऋ��� �ो� � � �ो� � � �� �� �� � � � तत।�����\n",
      "Generated Tokens :-  [164, 224, 164, 165, 224, 164, 165, 224, 164, 165, 224, 165, 139, 32, 224, 224, 164, 224, 165, 139, 224, 164, 224, 224, 165, 165, 224, 164, 224, 32, 224, 164, 164, 224, 165, 139, 32, 224, 164, 165, 224, 164, 224, 224, 164, 139, 224, 164, 224, 224, 32, 164, 224, 165, 139, 224, 32, 164, 32, 224, 32, 224, 224, 165, 139, 224, 32, 164, 32, 224, 32, 164, 224, 32, 224, 224, 32, 224, 224, 32, 224, 32, 224, 32, 224, 32, 224, 164, 164, 224, 164, 164, 224, 165, 164, 164, 164, 164, 164, 164]\n",
      "Evaluation Of himandri and bindu rani both friends were from karnals salwan village :-- \n",
      "Generated :-  ������������� ��������������� ������ ������������� ����� � � ����� � � �� �� �� � � � ��������������\n",
      "Iteration 300 : 2.479684352874756\n",
      "English : they were there\n",
      "Translation : वहां उन्होंने\n",
      "Predicted length :-  100\n",
      "Hindi Prediction :- �त�� ���� ��������� ो������ो��������������������������������������������������������������\n",
      "Generated Tokens :-  [164, 224, 164, 164, 164, 164, 32, 224, 164, 224, 224, 164, 224, 32, 224, 164, 139, 224, 164, 224, 224, 165, 224, 224, 224, 32, 224, 165, 139, 224, 224, 224, 224, 224, 224, 224, 165, 139, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164]\n",
      "Evaluation Of himandri and bindu rani both friends were from karnals salwan village :-- \n",
      "Generated :-  ������ ������ ����������� ��������������������������������������������������������������������������\n",
      "Iteration 400 : 2.491713285446167\n",
      "English : then you will receive a reference number\n",
      "Translation : इसके बाद आपको एक टोकन नंबर मिलेगा\n",
      "Predicted length :-  100\n",
      "Hindi Prediction :- �थथतो ऋ��त ��ऋतो ��त ����त� � � ������� ��� ��ोत�त����������\n",
      "Generated Tokens :-  [164, 224, 164, 165, 224, 164, 165, 224, 164, 164, 224, 165, 139, 32, 224, 164, 139, 224, 164, 224, 224, 164, 164, 32, 224, 164, 224, 224, 164, 139, 224, 164, 164, 224, 165, 139, 32, 224, 164, 224, 224, 164, 164, 32, 224, 164, 224, 224, 165, 224, 224, 164, 164, 224, 32, 224, 32, 224, 32, 224, 224, 164, 224, 224, 164, 224, 224, 164, 224, 32, 224, 164, 224, 224, 164, 32, 224, 164, 224, 224, 165, 139, 224, 164, 164, 224, 164, 224, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164]\n",
      "Evaluation Of himandri and bindu rani both friends were from karnals salwan village :-- \n",
      "Generated :-  ������������� ��������� ������������ ������ ���������� � � ���������� ����� ������������������������\n",
      "EPOCH :- 2\n",
      "Iteration 0 : 2.5495803356170654\n",
      "English : share videos\n",
      "Translation : वीडियो क्लिप शेयर किए\n",
      "Predicted length :-  31\n",
      "Hindi Prediction :- �त���� त������ ����������\n",
      "Generated Tokens :-  [164, 224, 164, 164, 164, 165, 165, 224, 164, 32, 164, 164, 32, 164, 164, 164, 164, 165, 165, 32, 164, 164, 164, 164, 165, 164, 224, 224, 224, 224, 164]\n",
      "Evaluation Of himandri and bindu rani both friends were from karnals salwan village :-- \n",
      "Generated :-  ��������� �� ������ �����������\n",
      "Iteration 100 : 2.668499231338501\n",
      "English : bajaj auto in search of a winner\n",
      "Translation : बजाज ऑटो  खेल में फिर से वापसी के आसार\n",
      "Predicted length :-  100\n",
      "Hindi Prediction :- ���������������६  त���� ������ बत�� थ�� त��थथ॥ त�� ��थ���त�\n",
      "Generated Tokens :-  [164, 224, 164, 139, 224, 164, 224, 224, 164, 224, 224, 164, 224, 165, 224, 224, 224, 224, 164, 224, 224, 165, 224, 32, 32, 224, 164, 164, 224, 165, 224, 224, 164, 224, 32, 224, 164, 224, 224, 165, 224, 224, 164, 224, 32, 224, 164, 139, 224, 164, 164, 224, 164, 224, 32, 224, 164, 165, 224, 165, 224, 32, 224, 164, 164, 224, 164, 224, 224, 164, 165, 224, 164, 165, 224, 165, 165, 32, 224, 164, 164, 224, 165, 224, 32, 224, 164, 224, 224, 164, 165, 224, 164, 224, 224, 164, 224, 164, 164, 164]\n",
      "Evaluation Of himandri and bindu rani both friends were from karnals salwan village :-- \n",
      "Generated :-  �����������������������  ��������� ��������� ��������� ������ ��������������� ������ ���������������\n",
      "Iteration 200 : 2.470726728439331\n",
      "English : this had led to strained relations between the two\n",
      "Translation : इससे दोनों के संबंधों में दरार आ गई।\n",
      "Predicted length :-  100\n",
      "Hindi Prediction :- �� ऋ� ॥ ��ो��॥�� तो थ��ऋ��� �ो� � � �ो� � � �� �� �� � � � तत।�����\n"
     ]
    }
   ],
   "source": [
    "transformer.train()\n",
    "transformer.to(device)\n",
    "total_loss = 0\n",
    "# num_epoch = 10\n",
    "num_epoch = 5\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    print(f\"EPOCH :- {epoch}\")\n",
    "    iterator = iter(train_loader)\n",
    "\n",
    "    for batch_num, batch in enumerate(iterator):\n",
    "        transformer.train()\n",
    "        eng_batch, hn_batch = batch\n",
    "        encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(eng_batch, hn_batch)\n",
    "        optim.zero_grad()\n",
    "\n",
    "        hn_prediction = transformer(eng_batch,\n",
    "                                     hn_batch,\n",
    "                                     encoder_self_attention_mask.to(device), \n",
    "                                     decoder_self_attention_mask.to(device), \n",
    "                                     decoder_cross_attention_mask.to(device))\n",
    "        \n",
    "        labels = transformer.decoder.sentence_embedding.batchTokenize(hn_batch, start=True, end=True)\n",
    "        loss = criterian(\n",
    "            hn_prediction.view(-1, len(hindi_to_index)).to(device),\n",
    "            labels.view(-1).to(device)\n",
    "        ).to(device)\n",
    "\n",
    "        valid_indices = torch.where(labels.view(-1) == hindi_to_index[padding_token], False, True)\n",
    "\n",
    "        loss = loss.sum()/valid_indices.sum()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "\n",
    "        if(batch_num%100 == 0):\n",
    "            print(f\"Iteration {batch_num} : {loss.item()}\")\n",
    "            print(f\"English : {eng_batch[0]}\")\n",
    "            print(f\"Translation : {hn_batch[0]}\")\n",
    "\n",
    "            hn_sentence_prediction = torch.argmax(hn_prediction[0], axis=1)\n",
    "            hindi_prediction = []\n",
    "            for i in hn_sentence_prediction:\n",
    "                if(i == hindi_to_index[end_token]):\n",
    "                    break\n",
    "                hindi_prediction.append(i.item())\n",
    "            print(\"Predicted length :- \",len(hindi_prediction))\n",
    "            print(f\"Hindi Prediction :- {tokens.decode(hindi_prediction, 'decoder')}\")\n",
    "\n",
    "            transformer.eval()\n",
    "            hn_sentence = (\"\",)\n",
    "            eng_sentence = (\"himandri and bindu rani both friends were from karnals salwan village\",)\n",
    "\n",
    "            checking = []\n",
    "            for word_counter in range(max_sequence_length):\n",
    "                encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(eng_sentence, hn_sentence)\n",
    "                predictions = transformer(eng_batch,\n",
    "                                            hn_batch,\n",
    "                                            encoder_self_attention_mask.to(device), \n",
    "                                            decoder_self_attention_mask.to(device), \n",
    "                                            decoder_cross_attention_mask.to(device))\n",
    "                next_token_index = torch.argmax(predictions[0][word_counter]).item()\n",
    "                next_token = tokens.decode([next_token_index], 'decoder')\n",
    "                if(next_token == \"<END>\"):\n",
    "                    break\n",
    "                checking.append(next_token_index)\n",
    "                hn_sentence = (hn_sentence[0]+next_token,)\n",
    "            print(\"Generated Tokens :- \",checking)\n",
    "            print(f\"Evaluation Of {eng_sentence[0]} :-- \")\n",
    "            print(\"Generated :- \",hn_sentence[0])\n",
    "            # print(f\"Checking :- \", tokens.decode(checking, 'decoder'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'transformer_model_2.pth'\n",
    "torch.save(transformer.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(d_model, \n",
    "                          max_seq_len, \n",
    "                          num_head, \n",
    "                          head_dim, \n",
    "                          drop_prob, \n",
    "                          english_to_index, \n",
    "                          ffn, hindi_to_index, \n",
    "                          encoder_type, decoder_type, \n",
    "                          n_layers, start_token, \n",
    "                          end_token, padding_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): Encoder(\n",
       "    (sentence_embedding): SentenceEmbedding(\n",
       "      (embedding): Embedding(55003, 512)\n",
       "      (position_encoder): PositionalEncoding()\n",
       "    )\n",
       "    (layers): SequentialEncoder(\n",
       "      (0): EncoderLayers(\n",
       "        (attention): MultiheadAttention(\n",
       "          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm): LayerNormalization()\n",
       "        (feedforward): PositionwiseFeedForward(\n",
       "          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (sentence_embedding): SentenceEmbedding(\n",
       "      (embedding): Embedding(75003, 512)\n",
       "      (position_encoder): PositionalEncoding()\n",
       "    )\n",
       "    (layers): SequentialDecoder(\n",
       "      (0): DecoderLayers(\n",
       "        (attention): MultiheadAttention(\n",
       "          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm): LayerNormalization()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (feedforward): PositionwiseFeedForward(\n",
       "          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (crossattention): CrossMultiHeadAttention(\n",
       "          (kv_layer): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (q_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=75003, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.load_state_dict(torch.load(model_path))\n",
    "transformer.to(device)\n",
    "transformer.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 gjgfgh\n",
      "3 gjgfgh\n",
      "3 gjgfgh\n",
      "break\n",
      "Generated :-  ('��',)\n"
     ]
    }
   ],
   "source": [
    "def predict(eng_sentence, transformer, max_sequence_length, device):\n",
    "    transformer.eval()\n",
    "    hn_sentence = (\"\",)\n",
    "\n",
    "    for word_counter in range(max_sequence_length):\n",
    "        encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(eng_sentence, hn_sentence)\n",
    "        predictions = transformer(eng_sentence,\n",
    "                                  hn_sentence,\n",
    "                                  encoder_self_attention_mask.to(device), \n",
    "                                  decoder_self_attention_mask.to(device), \n",
    "                                  decoder_cross_attention_mask.to(device))\n",
    "        # print(len(predictions.shape),\"gjgfgh\")\n",
    "        next_token_index = torch.argmax(predictions[0][word_counter]).item()\n",
    "        next_token = tokens.decode([next_token_index], 'decoder')\n",
    "        if next_token == \"<END>\":\n",
    "            print(\"break\")\n",
    "            break\n",
    "        hn_sentence = (hn_sentence[0] + next_token,)\n",
    "    \n",
    "    return hn_sentence\n",
    "\n",
    "# Example usage:\n",
    "eng_sentence = (\"hello how are you??\",)\n",
    "predicted_sentence = predict(eng_sentence, transformer, max_sequence_length, device)\n",
    "print(\"Generated :- \", predicted_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
